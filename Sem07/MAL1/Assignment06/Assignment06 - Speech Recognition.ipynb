{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Useful for running the notebook on Apple M1 chip to resolve circular dependency errors\n",
    "# !pip install tensorflow==2.14.0\n",
    "# !pip install keras==2.14.0\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T17:54:16.409407Z",
     "start_time": "2023-11-18T17:54:16.406952Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B0gJQnFVD8p2",
    "outputId": "651aa7c4-99f7-4127-cddf-73057288b94c",
    "ExecuteTime": {
     "end_time": "2023-11-18T18:02:10.910163Z",
     "start_time": "2023-11-18T17:54:16.411188Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.9857 - accuracy: 0.5705 - val_loss: 0.7434 - val_accuracy: 0.6944\n",
      "Epoch 2/50\n",
      "296/296 [==============================] - 9s 32ms/step - loss: 0.6764 - accuracy: 0.7150 - val_loss: 0.5487 - val_accuracy: 0.7913\n",
      "Epoch 3/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.5615 - accuracy: 0.7786 - val_loss: 0.4698 - val_accuracy: 0.8132\n",
      "Epoch 4/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.4825 - accuracy: 0.8085 - val_loss: 0.3976 - val_accuracy: 0.8520\n",
      "Epoch 5/50\n",
      "296/296 [==============================] - 9s 32ms/step - loss: 0.4287 - accuracy: 0.8321 - val_loss: 0.3691 - val_accuracy: 0.8628\n",
      "Epoch 6/50\n",
      "296/296 [==============================] - 10s 33ms/step - loss: 0.3925 - accuracy: 0.8500 - val_loss: 0.3404 - val_accuracy: 0.8755\n",
      "Epoch 7/50\n",
      "296/296 [==============================] - 10s 33ms/step - loss: 0.3682 - accuracy: 0.8584 - val_loss: 0.3288 - val_accuracy: 0.8767\n",
      "Epoch 8/50\n",
      "296/296 [==============================] - 10s 35ms/step - loss: 0.3504 - accuracy: 0.8651 - val_loss: 0.3039 - val_accuracy: 0.8920\n",
      "Epoch 9/50\n",
      "296/296 [==============================] - 10s 33ms/step - loss: 0.3295 - accuracy: 0.8750 - val_loss: 0.3041 - val_accuracy: 0.8904\n",
      "Epoch 10/50\n",
      "296/296 [==============================] - 10s 34ms/step - loss: 0.3091 - accuracy: 0.8838 - val_loss: 0.3015 - val_accuracy: 0.8860\n",
      "Epoch 11/50\n",
      "296/296 [==============================] - 10s 34ms/step - loss: 0.3188 - accuracy: 0.8788 - val_loss: 0.2931 - val_accuracy: 0.8898\n",
      "Epoch 12/50\n",
      "296/296 [==============================] - 10s 34ms/step - loss: 0.2738 - accuracy: 0.8951 - val_loss: 0.2893 - val_accuracy: 0.8920\n",
      "Epoch 13/50\n",
      "296/296 [==============================] - 10s 35ms/step - loss: 0.2637 - accuracy: 0.9022 - val_loss: 0.2477 - val_accuracy: 0.9120\n",
      "Epoch 14/50\n",
      "296/296 [==============================] - 10s 33ms/step - loss: 0.2424 - accuracy: 0.9083 - val_loss: 0.2646 - val_accuracy: 0.9022\n",
      "Epoch 15/50\n",
      "296/296 [==============================] - 10s 34ms/step - loss: 0.2317 - accuracy: 0.9088 - val_loss: 0.2543 - val_accuracy: 0.9095\n",
      "Epoch 16/50\n",
      "296/296 [==============================] - 9s 32ms/step - loss: 0.2194 - accuracy: 0.9157 - val_loss: 0.2792 - val_accuracy: 0.9079\n",
      "Epoch 17/50\n",
      "296/296 [==============================] - 9s 32ms/step - loss: 0.2031 - accuracy: 0.9235 - val_loss: 0.2591 - val_accuracy: 0.9111\n",
      "Epoch 18/50\n",
      "296/296 [==============================] - 10s 33ms/step - loss: 0.1989 - accuracy: 0.9249 - val_loss: 0.2487 - val_accuracy: 0.9145\n",
      "Epoch 19/50\n",
      "296/296 [==============================] - 10s 34ms/step - loss: 0.1880 - accuracy: 0.9273 - val_loss: 0.2384 - val_accuracy: 0.9212\n",
      "Epoch 20/50\n",
      "296/296 [==============================] - 10s 32ms/step - loss: 0.1805 - accuracy: 0.9361 - val_loss: 0.2587 - val_accuracy: 0.9168\n",
      "Epoch 21/50\n",
      "296/296 [==============================] - 9s 32ms/step - loss: 0.1668 - accuracy: 0.9357 - val_loss: 0.2592 - val_accuracy: 0.9203\n",
      "Epoch 22/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.1642 - accuracy: 0.9357 - val_loss: 0.2629 - val_accuracy: 0.9225\n",
      "Epoch 23/50\n",
      "296/296 [==============================] - 10s 32ms/step - loss: 0.1509 - accuracy: 0.9420 - val_loss: 0.2742 - val_accuracy: 0.9222\n",
      "Epoch 24/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.1797 - accuracy: 0.9320 - val_loss: 0.2635 - val_accuracy: 0.9231\n",
      "Epoch 25/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.1427 - accuracy: 0.9425 - val_loss: 0.2775 - val_accuracy: 0.9212\n",
      "Epoch 26/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.1424 - accuracy: 0.9453 - val_loss: 0.2690 - val_accuracy: 0.9260\n",
      "Epoch 27/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.1420 - accuracy: 0.9450 - val_loss: 0.2659 - val_accuracy: 0.9225\n",
      "Epoch 28/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.1307 - accuracy: 0.9509 - val_loss: 0.2713 - val_accuracy: 0.9269\n",
      "Epoch 29/50\n",
      "296/296 [==============================] - 9s 32ms/step - loss: 0.1204 - accuracy: 0.9524 - val_loss: 0.2818 - val_accuracy: 0.9273\n",
      "Epoch 30/50\n",
      "296/296 [==============================] - 11s 36ms/step - loss: 0.1178 - accuracy: 0.9542 - val_loss: 0.2814 - val_accuracy: 0.9234\n",
      "Epoch 31/50\n",
      "296/296 [==============================] - 10s 34ms/step - loss: 0.1123 - accuracy: 0.9574 - val_loss: 0.2791 - val_accuracy: 0.9209\n",
      "Epoch 32/50\n",
      "296/296 [==============================] - 10s 34ms/step - loss: 0.1144 - accuracy: 0.9584 - val_loss: 0.3028 - val_accuracy: 0.9219\n",
      "Epoch 33/50\n",
      "296/296 [==============================] - 10s 33ms/step - loss: 0.1166 - accuracy: 0.9563 - val_loss: 0.2932 - val_accuracy: 0.9253\n",
      "Epoch 34/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.0990 - accuracy: 0.9626 - val_loss: 0.3008 - val_accuracy: 0.9292\n",
      "Epoch 35/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.1001 - accuracy: 0.9626 - val_loss: 0.3246 - val_accuracy: 0.9225\n",
      "Epoch 36/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.0968 - accuracy: 0.9634 - val_loss: 0.3125 - val_accuracy: 0.9253\n",
      "Epoch 37/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.1006 - accuracy: 0.9599 - val_loss: 0.2934 - val_accuracy: 0.9314\n",
      "Epoch 38/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.0822 - accuracy: 0.9679 - val_loss: 0.3132 - val_accuracy: 0.9273\n",
      "Epoch 39/50\n",
      "296/296 [==============================] - 9s 32ms/step - loss: 0.0925 - accuracy: 0.9647 - val_loss: 0.3132 - val_accuracy: 0.9295\n",
      "Epoch 40/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.0844 - accuracy: 0.9691 - val_loss: 0.3067 - val_accuracy: 0.9317\n",
      "Epoch 41/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.0786 - accuracy: 0.9704 - val_loss: 0.3396 - val_accuracy: 0.9238\n",
      "Epoch 42/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.0825 - accuracy: 0.9680 - val_loss: 0.3332 - val_accuracy: 0.9260\n",
      "Epoch 43/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.0852 - accuracy: 0.9660 - val_loss: 0.3581 - val_accuracy: 0.9241\n",
      "Epoch 44/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.0733 - accuracy: 0.9697 - val_loss: 0.3697 - val_accuracy: 0.9304\n",
      "Epoch 45/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.0749 - accuracy: 0.9700 - val_loss: 0.3524 - val_accuracy: 0.9279\n",
      "Epoch 46/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.0814 - accuracy: 0.9682 - val_loss: 0.3743 - val_accuracy: 0.9288\n",
      "Epoch 47/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.0675 - accuracy: 0.9752 - val_loss: 0.3663 - val_accuracy: 0.9307\n",
      "Epoch 48/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.0672 - accuracy: 0.9739 - val_loss: 0.3777 - val_accuracy: 0.9282\n",
      "Epoch 49/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.0648 - accuracy: 0.9739 - val_loss: 0.3674 - val_accuracy: 0.9279\n",
      "Epoch 50/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.1417 - accuracy: 0.9478 - val_loss: 0.3219 - val_accuracy: 0.9307\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "X = np.load('XSound.npy')\n",
    "Y = np.load('YSound.npy')\n",
    "\n",
    "# Normalizing the data\n",
    "X = X / np.max(X)\n",
    "\n",
    "# Reshaping the data to include a channel dimension\n",
    "X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
    "\n",
    "# Splitting the data into training, validation, and test sets\n",
    "X_temp, X_test, Y_temp, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_temp, Y_temp, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "# Model configuration\n",
    "batch_size = 32\n",
    "img_width, img_height, img_num_channels = 62, 65, 1\n",
    "loss_function = 'sparse_categorical_crossentropy'\n",
    "no_epochs = 50\n",
    "optimizer = Adam()\n",
    "no_classes = 4\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(img_width, img_height, img_num_channels)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(no_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=loss_function,\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit data to model\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=no_epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val, Y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Make predictions\n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "test_predicted_classes = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(Y_test, test_predicted_classes)\n",
    "\n",
    "# Plotting using seaborn\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 580
    },
    "id": "9m9WYjvFV4sx",
    "outputId": "dbd39382-821f-40eb-89e9-a145ff771459",
    "ExecuteTime": {
     "end_time": "2023-11-18T18:02:11.920544Z",
     "start_time": "2023-11-18T18:02:10.906152Z"
    }
   },
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 1s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x700 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Comment on the results\n",
    "The confusion matrix shows the classification rates of our model for the classes. The results are:\n",
    "* Class 0: 675 true positives, with some confusion with Class 1 (116 times - this is the biggest confusion out of all combinations).\n",
    "* Class 1: 725 true positives, with a few confusions with Class 0 (37 times) and Class 2 (18 times).\n",
    "* Class 2: 700 true positives, with a few confusions with Class 0 (30 times).\n",
    "* Class 3: 781 true positives, with a few confusions with other classes (15 instances misclassified as Class 0).\n",
    " \n",
    "Overall the models seems to be a good fit, as the matrix shows high number of true positives on the diagonals"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "__(c)__ Choose one other algorithm from the course, and redo (a) and (b) using this algorithm. Supply a brief discussion of why we would expect this algorithm to do better/worse than the CNN."
   ],
   "metadata": {
    "id": "Qo2Q4tVQg9Kd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "D1PqiTIIg9FT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Model configuration\n",
    "batch_size = 32\n",
    "no_epochs = 50\n",
    "no_classes = 4\n",
    "\n",
    "# Dense network model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(62, 65)))  # Flattening the input\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(no_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit data to model\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=no_epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val, Y_val))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dbzi46FFftZh",
    "outputId": "81b6ad3d-52f1-442a-ac2e-d4271eab123e",
    "ExecuteTime": {
     "end_time": "2023-11-18T18:02:41.519148Z",
     "start_time": "2023-11-18T18:02:11.923021Z"
    }
   },
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 1.0547 - accuracy: 0.5543 - val_loss: 0.7877 - val_accuracy: 0.7189\n",
      "Epoch 2/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.7541 - accuracy: 0.7005 - val_loss: 0.6624 - val_accuracy: 0.7602\n",
      "Epoch 3/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.6563 - accuracy: 0.7418 - val_loss: 0.6195 - val_accuracy: 0.7665\n",
      "Epoch 4/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.6011 - accuracy: 0.7694 - val_loss: 0.5634 - val_accuracy: 0.7878\n",
      "Epoch 5/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.5522 - accuracy: 0.7758 - val_loss: 0.5439 - val_accuracy: 0.7878\n",
      "Epoch 6/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.5121 - accuracy: 0.7979 - val_loss: 0.5203 - val_accuracy: 0.7983\n",
      "Epoch 7/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.4776 - accuracy: 0.8115 - val_loss: 0.4954 - val_accuracy: 0.8180\n",
      "Epoch 8/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.4493 - accuracy: 0.8284 - val_loss: 0.4806 - val_accuracy: 0.8272\n",
      "Epoch 9/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.4273 - accuracy: 0.8354 - val_loss: 0.4757 - val_accuracy: 0.8323\n",
      "Epoch 10/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.4074 - accuracy: 0.8446 - val_loss: 0.4666 - val_accuracy: 0.8351\n",
      "Epoch 11/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.3984 - accuracy: 0.8461 - val_loss: 0.4630 - val_accuracy: 0.8355\n",
      "Epoch 12/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.3661 - accuracy: 0.8586 - val_loss: 0.4565 - val_accuracy: 0.8335\n",
      "Epoch 13/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.3480 - accuracy: 0.8635 - val_loss: 0.4600 - val_accuracy: 0.8361\n",
      "Epoch 14/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.3486 - accuracy: 0.8665 - val_loss: 0.4461 - val_accuracy: 0.8412\n",
      "Epoch 15/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.3354 - accuracy: 0.8694 - val_loss: 0.4518 - val_accuracy: 0.8431\n",
      "Epoch 16/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.3191 - accuracy: 0.8735 - val_loss: 0.4419 - val_accuracy: 0.8453\n",
      "Epoch 17/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.3088 - accuracy: 0.8814 - val_loss: 0.4432 - val_accuracy: 0.8520\n",
      "Epoch 18/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.2942 - accuracy: 0.8848 - val_loss: 0.4579 - val_accuracy: 0.8482\n",
      "Epoch 19/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.2916 - accuracy: 0.8893 - val_loss: 0.4544 - val_accuracy: 0.8456\n",
      "Epoch 20/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.2833 - accuracy: 0.8903 - val_loss: 0.4421 - val_accuracy: 0.8577\n",
      "Epoch 21/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.2732 - accuracy: 0.8948 - val_loss: 0.4561 - val_accuracy: 0.8551\n",
      "Epoch 22/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.2646 - accuracy: 0.8993 - val_loss: 0.4553 - val_accuracy: 0.8548\n",
      "Epoch 23/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.2567 - accuracy: 0.9035 - val_loss: 0.4550 - val_accuracy: 0.8618\n",
      "Epoch 24/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.2510 - accuracy: 0.9024 - val_loss: 0.4666 - val_accuracy: 0.8637\n",
      "Epoch 25/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.2539 - accuracy: 0.9065 - val_loss: 0.4559 - val_accuracy: 0.8615\n",
      "Epoch 26/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.2332 - accuracy: 0.9119 - val_loss: 0.4595 - val_accuracy: 0.8659\n",
      "Epoch 27/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.2273 - accuracy: 0.9123 - val_loss: 0.4766 - val_accuracy: 0.8621\n",
      "Epoch 28/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.2278 - accuracy: 0.9136 - val_loss: 0.4869 - val_accuracy: 0.8599\n",
      "Epoch 29/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.2084 - accuracy: 0.9233 - val_loss: 0.4765 - val_accuracy: 0.8656\n",
      "Epoch 30/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.2117 - accuracy: 0.9216 - val_loss: 0.4919 - val_accuracy: 0.8628\n",
      "Epoch 31/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.2075 - accuracy: 0.9224 - val_loss: 0.4861 - val_accuracy: 0.8682\n",
      "Epoch 32/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.1966 - accuracy: 0.9305 - val_loss: 0.4979 - val_accuracy: 0.8675\n",
      "Epoch 33/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.1938 - accuracy: 0.9279 - val_loss: 0.4902 - val_accuracy: 0.8618\n",
      "Epoch 34/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.1857 - accuracy: 0.9313 - val_loss: 0.4929 - val_accuracy: 0.8669\n",
      "Epoch 35/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.1873 - accuracy: 0.9313 - val_loss: 0.5040 - val_accuracy: 0.8650\n",
      "Epoch 36/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.1872 - accuracy: 0.9328 - val_loss: 0.4962 - val_accuracy: 0.8685\n",
      "Epoch 37/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.1767 - accuracy: 0.9348 - val_loss: 0.5214 - val_accuracy: 0.8669\n",
      "Epoch 38/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.1635 - accuracy: 0.9408 - val_loss: 0.5054 - val_accuracy: 0.8707\n",
      "Epoch 39/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.1769 - accuracy: 0.9373 - val_loss: 0.5274 - val_accuracy: 0.8628\n",
      "Epoch 40/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.1571 - accuracy: 0.9427 - val_loss: 0.5383 - val_accuracy: 0.8631\n",
      "Epoch 41/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.1667 - accuracy: 0.9369 - val_loss: 0.5275 - val_accuracy: 0.8717\n",
      "Epoch 42/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.1555 - accuracy: 0.9435 - val_loss: 0.5175 - val_accuracy: 0.8694\n",
      "Epoch 43/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.1528 - accuracy: 0.9457 - val_loss: 0.5424 - val_accuracy: 0.8698\n",
      "Epoch 44/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.1485 - accuracy: 0.9461 - val_loss: 0.5185 - val_accuracy: 0.8745\n",
      "Epoch 45/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.1466 - accuracy: 0.9517 - val_loss: 0.5580 - val_accuracy: 0.8675\n",
      "Epoch 46/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.1524 - accuracy: 0.9462 - val_loss: 0.5397 - val_accuracy: 0.8682\n",
      "Epoch 47/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.1486 - accuracy: 0.9470 - val_loss: 0.5574 - val_accuracy: 0.8691\n",
      "Epoch 48/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.1428 - accuracy: 0.9482 - val_loss: 0.5571 - val_accuracy: 0.8701\n",
      "Epoch 49/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.1372 - accuracy: 0.9522 - val_loss: 0.5778 - val_accuracy: 0.8672\n",
      "Epoch 50/50\n",
      "296/296 [==============================] - 1s 2ms/step - loss: 0.1392 - accuracy: 0.9530 - val_loss: 0.5814 - val_accuracy: 0.8704\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the data\n",
    "X = np.load('XSound.npy')\n",
    "Y = np.load('YSound.npy')\n",
    "\n",
    "# Normalizing the data\n",
    "X = X / np.max(X)\n",
    "\n",
    "# Reshaping the data for RNN input\n",
    "# Assuming X.shape is in the form of (samples, time_steps, features)\n",
    "# If it's not, you might need to reshape it accordingly\n",
    "\n",
    "# Splitting the data into training, validation, and test sets\n",
    "X_temp, X_test, Y_temp, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_temp, Y_temp, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "# Model configuration\n",
    "batch_size = 32\n",
    "loss_function = 'sparse_categorical_crossentropy'\n",
    "no_epochs = 50\n",
    "optimizer = Adam()\n",
    "no_classes = 4\n",
    "\n",
    "# Define the RNN model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, input_shape=(X.shape[1], X.shape[2])))  # Adjust input_shape based on your data\n",
    "model.add(LSTM(32, return_sequences=False))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(no_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=loss_function,\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit data to model\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=no_epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_val, Y_val))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w35BQqiMm5tK",
    "outputId": "f3923f67-49ff-4563-c002-d0c46843ef69",
    "ExecuteTime": {
     "end_time": "2023-11-18T18:10:16.886336Z",
     "start_time": "2023-11-18T18:02:41.513532Z"
    }
   },
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "296/296 [==============================] - 11s 32ms/step - loss: 1.1834 - accuracy: 0.4239 - val_loss: 0.9109 - val_accuracy: 0.5921\n",
      "Epoch 2/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.8867 - accuracy: 0.5961 - val_loss: 1.3181 - val_accuracy: 0.5038\n",
      "Epoch 3/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.8025 - accuracy: 0.6344 - val_loss: 0.6519 - val_accuracy: 0.6849\n",
      "Epoch 4/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.6535 - accuracy: 0.6796 - val_loss: 0.5938 - val_accuracy: 0.7081\n",
      "Epoch 5/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.5965 - accuracy: 0.7104 - val_loss: 0.7197 - val_accuracy: 0.6512\n",
      "Epoch 6/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.6220 - accuracy: 0.7088 - val_loss: 0.5368 - val_accuracy: 0.7614\n",
      "Epoch 7/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.5379 - accuracy: 0.7561 - val_loss: 0.5022 - val_accuracy: 0.7751\n",
      "Epoch 8/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.4892 - accuracy: 0.7943 - val_loss: 0.5293 - val_accuracy: 0.8081\n",
      "Epoch 9/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.5014 - accuracy: 0.7769 - val_loss: 0.4373 - val_accuracy: 0.8240\n",
      "Epoch 10/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.4365 - accuracy: 0.8233 - val_loss: 0.4286 - val_accuracy: 0.8418\n",
      "Epoch 11/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.4108 - accuracy: 0.8441 - val_loss: 0.3930 - val_accuracy: 0.8517\n",
      "Epoch 12/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.3903 - accuracy: 0.8555 - val_loss: 0.3879 - val_accuracy: 0.8532\n",
      "Epoch 13/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.3807 - accuracy: 0.8607 - val_loss: 0.4177 - val_accuracy: 0.8361\n",
      "Epoch 14/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.3725 - accuracy: 0.8640 - val_loss: 0.3338 - val_accuracy: 0.8815\n",
      "Epoch 15/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.3354 - accuracy: 0.8779 - val_loss: 0.3577 - val_accuracy: 0.8698\n",
      "Epoch 16/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.3359 - accuracy: 0.8759 - val_loss: 0.3394 - val_accuracy: 0.8764\n",
      "Epoch 17/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.3078 - accuracy: 0.8899 - val_loss: 0.3238 - val_accuracy: 0.8853\n",
      "Epoch 18/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.3053 - accuracy: 0.8932 - val_loss: 0.3584 - val_accuracy: 0.8685\n",
      "Epoch 19/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.2836 - accuracy: 0.8974 - val_loss: 0.3108 - val_accuracy: 0.8907\n",
      "Epoch 20/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.2704 - accuracy: 0.9016 - val_loss: 0.2877 - val_accuracy: 0.9006\n",
      "Epoch 21/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.2872 - accuracy: 0.8962 - val_loss: 0.3429 - val_accuracy: 0.8758\n",
      "Epoch 22/50\n",
      "296/296 [==============================] - 9s 30ms/step - loss: 0.2848 - accuracy: 0.8980 - val_loss: 0.2872 - val_accuracy: 0.8971\n",
      "Epoch 23/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.2488 - accuracy: 0.9124 - val_loss: 0.2905 - val_accuracy: 0.8993\n",
      "Epoch 24/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.2667 - accuracy: 0.9051 - val_loss: 0.2653 - val_accuracy: 0.9104\n",
      "Epoch 25/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.2323 - accuracy: 0.9197 - val_loss: 0.2620 - val_accuracy: 0.9161\n",
      "Epoch 26/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.2333 - accuracy: 0.9208 - val_loss: 0.2824 - val_accuracy: 0.9044\n",
      "Epoch 27/50\n",
      "296/296 [==============================] - 9s 31ms/step - loss: 0.2194 - accuracy: 0.9229 - val_loss: 0.2492 - val_accuracy: 0.9095\n",
      "Epoch 28/50\n",
      "296/296 [==============================] - 9s 32ms/step - loss: 0.2154 - accuracy: 0.9242 - val_loss: 0.2675 - val_accuracy: 0.9104\n",
      "Epoch 29/50\n",
      "296/296 [==============================] - 9s 32ms/step - loss: 0.2081 - accuracy: 0.9251 - val_loss: 0.2659 - val_accuracy: 0.9120\n",
      "Epoch 30/50\n",
      "296/296 [==============================] - 9s 30ms/step - loss: 0.2138 - accuracy: 0.9236 - val_loss: 0.2469 - val_accuracy: 0.9088\n",
      "Epoch 31/50\n",
      "296/296 [==============================] - 9s 30ms/step - loss: 0.1921 - accuracy: 0.9321 - val_loss: 0.2189 - val_accuracy: 0.9244\n",
      "Epoch 32/50\n",
      "296/296 [==============================] - 9s 30ms/step - loss: 0.1882 - accuracy: 0.9350 - val_loss: 0.2546 - val_accuracy: 0.9098\n",
      "Epoch 33/50\n",
      "296/296 [==============================] - 9s 30ms/step - loss: 0.1837 - accuracy: 0.9358 - val_loss: 0.2228 - val_accuracy: 0.9228\n",
      "Epoch 34/50\n",
      "296/296 [==============================] - 9s 30ms/step - loss: 0.1717 - accuracy: 0.9389 - val_loss: 0.2293 - val_accuracy: 0.9228\n",
      "Epoch 35/50\n",
      "296/296 [==============================] - 9s 30ms/step - loss: 0.1895 - accuracy: 0.9308 - val_loss: 0.2311 - val_accuracy: 0.9215\n",
      "Epoch 36/50\n",
      "296/296 [==============================] - 9s 30ms/step - loss: 0.1726 - accuracy: 0.9416 - val_loss: 0.2174 - val_accuracy: 0.9282\n",
      "Epoch 37/50\n",
      "296/296 [==============================] - 9s 30ms/step - loss: 0.1587 - accuracy: 0.9442 - val_loss: 0.2651 - val_accuracy: 0.9107\n",
      "Epoch 38/50\n",
      "296/296 [==============================] - 9s 30ms/step - loss: 0.1642 - accuracy: 0.9429 - val_loss: 0.2015 - val_accuracy: 0.9317\n",
      "Epoch 39/50\n",
      "296/296 [==============================] - 9s 30ms/step - loss: 0.1481 - accuracy: 0.9462 - val_loss: 0.1977 - val_accuracy: 0.9330\n",
      "Epoch 40/50\n",
      "296/296 [==============================] - 9s 30ms/step - loss: 0.1365 - accuracy: 0.9499 - val_loss: 0.2172 - val_accuracy: 0.9304\n",
      "Epoch 41/50\n",
      "296/296 [==============================] - 9s 30ms/step - loss: 0.1428 - accuracy: 0.9462 - val_loss: 0.2457 - val_accuracy: 0.9158\n",
      "Epoch 42/50\n",
      "296/296 [==============================] - 9s 30ms/step - loss: 0.1453 - accuracy: 0.9483 - val_loss: 0.1973 - val_accuracy: 0.9377\n",
      "Epoch 43/50\n",
      "296/296 [==============================] - 9s 30ms/step - loss: 0.1410 - accuracy: 0.9477 - val_loss: 0.1925 - val_accuracy: 0.9339\n",
      "Epoch 44/50\n",
      "296/296 [==============================] - 9s 30ms/step - loss: 0.1427 - accuracy: 0.9473 - val_loss: 0.2072 - val_accuracy: 0.9352\n",
      "Epoch 45/50\n",
      "296/296 [==============================] - 9s 30ms/step - loss: 0.1232 - accuracy: 0.9551 - val_loss: 0.2111 - val_accuracy: 0.9377\n",
      "Epoch 46/50\n",
      "296/296 [==============================] - 9s 30ms/step - loss: 0.1252 - accuracy: 0.9554 - val_loss: 0.1912 - val_accuracy: 0.9374\n",
      "Epoch 47/50\n",
      "296/296 [==============================] - 9s 30ms/step - loss: 0.1216 - accuracy: 0.9543 - val_loss: 0.1942 - val_accuracy: 0.9428\n",
      "Epoch 48/50\n",
      "296/296 [==============================] - 9s 30ms/step - loss: 0.1344 - accuracy: 0.9535 - val_loss: 0.2077 - val_accuracy: 0.9323\n",
      "Epoch 49/50\n",
      "296/296 [==============================] - 9s 30ms/step - loss: 0.1281 - accuracy: 0.9536 - val_loss: 0.2368 - val_accuracy: 0.9238\n",
      "Epoch 50/50\n",
      "296/296 [==============================] - 9s 30ms/step - loss: 0.1176 - accuracy: 0.9584 - val_loss: 0.1853 - val_accuracy: 0.9479\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# New Section"
   ],
   "metadata": {
    "id": "DS_IKSe3SmZa"
   }
  }
 ]
}
